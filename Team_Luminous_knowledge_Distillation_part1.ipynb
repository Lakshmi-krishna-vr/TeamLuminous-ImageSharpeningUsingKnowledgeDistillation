{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lakshmi-krishna-vr/TeamLuminous-ImageSharpeningUsingKnowledgeDistillation/blob/main/Team_Luminous_knowledge_Distillation_part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jk07FVknUfSw"
      },
      "outputs": [],
      "source": [
        "# Download and unzip the DIV2K dataset\n",
        "url = \"http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\"\n",
        "print(\"ðŸ“¥ Downloading DIV2K HR images...\")\n",
        "r = requests.get(url)\n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall(\"DIV2K_train_HR\")\n",
        "print(\"âœ… Dataset downloaded and extracted!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8L8sUMqUfSx",
        "outputId": "0637f59e-54c8-4e94-8aad-297ea3757311"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 700 training images.\n",
            "Found 100 testing images.\n"
          ]
        }
      ],
      "source": [
        "# --- Data Splitting ---\n",
        "# Split the dataset for training and testing to ensure fair evaluation\n",
        "DATASET_PATH = 'DIV2K_train_HR/DIV2K_train_HR'\n",
        "all_files = sorted(glob.glob(os.path.join(DATASET_PATH, \"*.png\")))\n",
        "\n",
        "# Use 200 images for training and 100 for testing, as requested\n",
        "train_files = all_files[:700]\n",
        "test_files = all_files[700:800] # A benchmark set of 100 images\n",
        "\n",
        "print(f\"Found {len(train_files)} training images.\")\n",
        "print(f\"Found {len(test_files)} testing images.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MZo-qpoUfSx"
      },
      "outputs": [],
      "source": [
        "class SharpeningDataset(Dataset):\n",
        "    \"\"\"Custom Dataset for creating blurry/sharp image pairs.\"\"\"\n",
        "    def __init__(self, image_paths, patch_size=256):\n",
        "        self.image_paths = image_paths\n",
        "        self.patch_size = patch_size\n",
        "        self.to_tensor = ToTensor()\n",
        "        self.scale_factor = 2 # Defines the initial downscaling factor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            # Load the high-resolution (HR) ground truth image\n",
        "            hr_image = Image.open(self.image_paths[idx]).convert('RGB')\n",
        "            w, h = hr_image.size\n",
        "\n",
        "            # Ensure image is large enough, resize if necessary\n",
        "            if w < self.patch_size or h < self.patch_size:\n",
        "                hr_image = hr_image.resize((self.patch_size, self.patch_size), Image.BICUBIC)\n",
        "                w, h = hr_image.size\n",
        "\n",
        "            # Take a random crop for data augmentation\n",
        "            rand_w = np.random.randint(0, w - self.patch_size + 1)\n",
        "            rand_h = np.random.randint(0, h - self.patch_size + 1)\n",
        "            hr_patch = hr_image.crop((rand_w, rand_h, rand_w + self.patch_size, rand_h + self.patch_size))\n",
        "\n",
        "            # Create the blurry (LR) input image\n",
        "            # 1. Downscale the image\n",
        "            lr_size = (self.patch_size // self.scale_factor, self.patch_size // self.scale_factor)\n",
        "            lr_patch = hr_patch.resize(lr_size, Image.BICUBIC)\n",
        "            # 2. Apply a strong Gaussian blur\n",
        "            lr_patch = lr_patch.filter(ImageFilter.GaussianBlur(radius=1.5))\n",
        "\n",
        "            # 3. Upscale it back to the original patch size\n",
        "            lr_patch = lr_patch.resize((self.patch_size, self.patch_size), Image.BICUBIC)\n",
        "\n",
        "            # Convert images to PyTorch tensors\n",
        "            hr_tensor = self.to_tensor(hr_patch)\n",
        "            lr_tensor = self.to_tensor(lr_patch)\n",
        "            return {'lr': lr_tensor, 'hr': hr_tensor}\n",
        "        except Exception as e:\n",
        "            print(f\"[Dataset Error] at index {idx}: {e}\")\n",
        "            raise e  # Let it crash visibly if needed\n",
        "\n",
        "# Create DataLoaders\n",
        "patch_size = 256\n",
        "batch_size = 5\n",
        "\n",
        "train_dataset = SharpeningDataset(train_files, patch_size=patch_size)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "test_dataset = SharpeningDataset(test_files, patch_size=patch_size)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0) # Batch size 1 for testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qF3Xb-bPUfSx",
        "outputId": "ea214cb1-7ca6-4d4b-a7c9-60425a408f3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "12.1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.version.cuda)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvhFMaZVUfSy",
        "outputId": "3fa5fa7d-eae8-486a-d509-3fad021aaee7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA Available: True\n",
            "GPU Name: NVIDIA GeForce RTX 4050 Laptop GPU\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(\"CUDA Available:\", torch.cuda.is_available())\n",
        "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzAkhs8fUfSy",
        "outputId": "43fcec49-4ff8-42f4-db4c-4781e6222d7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Jul  3 17:30:16 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 555.99                 Driver Version: 555.99         CUDA Version: 12.5     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce RTX 4050 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
            "| N/A   43C    P3             11W /   40W |       8MiB /   6141MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A     12980    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1hCE49fUfSy",
        "outputId": "c037610e-85aa-4380-9e3a-f776a3865ce3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA Available: True\n",
            "GPU Name: NVIDIA GeForce RTX 4050 Laptop GPU\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(\"CUDA Available:\", torch.cuda.is_available())\n",
        "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YYFPnU1UfSy",
        "outputId": "f640bed4-e19b-4f2e-82ab-727ba9bfb7bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher Model Parameters: 2,561,187\n",
            "Student Model Parameters: 13,571\n",
            "The student model is ~188.7x smaller than the teacher model.\n"
          ]
        }
      ],
      "source": [
        "class TeacherModel(nn.Module):\n",
        "    \"\"\"A high-capacity model to serve as the 'teacher'.\"\"\"\n",
        "    def __init__(self):\n",
        "        super(TeacherModel, self).__init__()\n",
        "        # Deeper and wider architecture for higher performance\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 384, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(384, 192, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(192, 192, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(192, 96, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(96, 48, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(48, 3, kernel_size=3, padding=1)\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Residual connection helps stabilize training\n",
        "        return x + self.layers(x)\n",
        "\n",
        "class StudentModel(nn.Module):\n",
        "    \"\"\"An ultra-lightweight model to be trained via distillation.\"\"\"\n",
        "    def __init__(self):\n",
        "        super(StudentModel, self).__init__()\n",
        "        # Fewer layers and channels to be lightweight and fast\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 128, kernel_size=3, padding=1),     # ~3.6K\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 64, kernel_size=1),               # ~8.3K\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 3, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Residual connection is crucial for good performance\n",
        "        return x + self.layers(x)\n",
        "\n",
        "# Instantiate models to check parameter counts\n",
        "teacher = TeacherModel()\n",
        "student = StudentModel()\n",
        "\n",
        "teacher_params = sum(p.numel() for p in teacher.parameters() if p.requires_grad)\n",
        "student_params = sum(p.numel() for p in student.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"Teacher Model Parameters: {teacher_params:,}\")\n",
        "print(f\"Student Model Parameters: {student_params:,}\")\n",
        "print(f\"The student model is ~{teacher_params/student_params:.1f}x smaller than the teacher model.\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}